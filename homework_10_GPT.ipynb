{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {
    "id": "1dba7c0d"
   },
   "source": [
    "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ ‚Ññ 10. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f21d5e",
   "metadata": {
    "id": "76f21d5e"
   },
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1 (8 –±–∞–ª–ª–æ–≤).\n",
    "\n",
    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥–æ–æ–±—É—á–∞—Ç—å GPT –Ω–∞ –∫–∞–∫–æ–º-—Ç–æ –¥—Ä—É–≥–æ–º —Ç–µ–∫—Å—Ç–µ (–º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ª—é–±—ã–µ —Å—Ç–∏—Ö–∏ –∏–ª–∏ –∫–∞–∫–∏–µ-—Ç–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –≤–µ—â–∏ –≤—Ä–æ–¥–µ –∞–Ω–µ–∫–¥–æ—Ç–æ–≤, —Ç–µ–æ—Ä–∏–π –∑–∞–≥–æ–≤–æ—Ä–æ–≤, –ø–æ—Å—Ç–æ–≤ –≤ –ø–æ–º–æ–µ—á–Ω—ã—Ö —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª–∞—Ö, —Ç–µ–∫—Å—Ç–æ–≤ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–æ–≤ –∏ –°–ú–ò —Å –≤—ã—Ä–∞–∑–∏—Ç–µ–ª—å–Ω—ã–º —Å—Ç–∏–ª–µ–º). \n",
    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (beam search, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, top_k –∏ —Ç–ø). –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤ —Ç–µ—Ç—Ä–∞–¥–∫–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–∏—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444e3fe",
   "metadata": {
    "id": "2444e3fe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "model_path = 'sberbank-ai/rugpt3medium_based_on_gpt2'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zzyJYbkM4Qnr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzyJYbkM4Qnr",
    "outputId": "bad5f150-7b6b-4917-fdfb-876d0abb5fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9cceb",
   "metadata": {},
   "source": [
    "–í –≤–∏–¥–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏ –∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏, –≥–¥–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –±—É–¥–µ—Ç –∑–∞–¥–∞–Ω —Ç–æ–∫–µ–Ω —Å—Ç–∏–ª—è [neutral] –∏–ª–∏ [toxic]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bd89b",
   "metadata": {
    "id": "f07bd89b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '/content/drive/MyDrive/labeled.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data['label'] = data['toxic'].map({1: 'toxic', 0: 'neutral'})\n",
    "data['input'] = data['label'].apply(lambda x: '[' + x + '] ') + data['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fDLp68J4mce",
   "metadata": {
    "id": "5fDLp68J4mce"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(data, shuffle=True, stratify=data['label'])\n",
    "train_data = train_data['input'].values.tolist()\n",
    "val_data = val_data['input'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Q1wWV62aLMw",
   "metadata": {
    "id": "6Q1wWV62aLMw"
   },
   "outputs": [],
   "source": [
    "train_path = 'odno_train_dataset.txt'\n",
    "with open(train_path, \"w\") as f:\n",
    "    f.write('\\n'.join(train_data))\n",
    "    \n",
    "val_path = 'odno_val_dataset.txt'\n",
    "with open(val_path, \"w\") as f:\n",
    "    f.write('\\n'.join(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EMngnxtCaJaB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMngnxtCaJaB",
    "outputId": "718498bc-5ef6-494d-c0cb-40de3b47786e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "train_dataset = TextDataset(tokenizer=tokenizer,\n",
    "                            file_path=train_path,\n",
    "                            block_size=64, \n",
    "                            overwrite_cache=True)\n",
    "\n",
    "val_dataset = TextDataset(tokenizer=tokenizer,\n",
    "                          file_path=val_path,\n",
    "                          block_size=64, \n",
    "                          overwrite_cache=True)\n",
    "  \n",
    "# —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–æ–¥–∞–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω–æ–º –µ–π –≤–∏–¥–µ\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H6yWC9qZDE9I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6yWC9qZDE9I",
    "outputId": "80606a00-0457-45ae-99c1-a9dfaddb2e46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8377, 2781)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ZhjVUn_075",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11ZhjVUn_075",
    "outputId": "51c5a368-8526-4f86-8411-b91f54857552"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 2\n",
    "\n",
    "training_arguments = TrainingArguments(output_dir='./models/',\n",
    "                                       per_device_train_batch_size=batch_size, \n",
    "                                       per_device_eval_batch_size=batch_size,  \n",
    "                                       num_train_epochs=epochs,\n",
    "                                       logging_dir='./logs',\n",
    "                                       logging_steps=50,\n",
    "                                       eval_steps=200,\n",
    "                                       save_steps=1000,\n",
    "                                       warmup_steps=500,\n",
    "                                       report_to='none',\n",
    "                                       evaluation_strategy='steps'\n",
    "                                       )\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=val_dataset,\n",
    "                  data_collator=data_collator, \n",
    "                  args=training_arguments,\n",
    "                  optimizers = (torch.optim.AdamW(model.parameters(), lr=1e-5),None)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DieW-0yh_05k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DieW-0yh_05k",
    "outputId": "1a1d60e8-9b64-4a74-ab53-a3c2cbc91f23",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8377\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4190\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4190' max='4190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4190/4190 1:20:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.762605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.645300</td>\n",
       "      <td>3.762216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.695400</td>\n",
       "      <td>3.746014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.786400</td>\n",
       "      <td>3.742364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.680500</td>\n",
       "      <td>3.739798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.716900</td>\n",
       "      <td>3.735901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.766300</td>\n",
       "      <td>3.728274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.744700</td>\n",
       "      <td>3.728084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.734600</td>\n",
       "      <td>3.724246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.689600</td>\n",
       "      <td>3.721359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.551100</td>\n",
       "      <td>3.725362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.523100</td>\n",
       "      <td>3.726605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.557200</td>\n",
       "      <td>3.726232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.477400</td>\n",
       "      <td>3.724417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.496800</td>\n",
       "      <td>3.723078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>3.537800</td>\n",
       "      <td>3.722165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>3.509900</td>\n",
       "      <td>3.721306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>3.548200</td>\n",
       "      <td>3.720602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>3.498800</td>\n",
       "      <td>3.721849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.533600</td>\n",
       "      <td>3.720308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./models/checkpoint-1000\n",
      "Configuration saved in ./models/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./models/checkpoint-2000\n",
      "Configuration saved in ./models/checkpoint-2000/config.json\n",
      "Model weights saved in ./models/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./models/checkpoint-3000\n",
      "Configuration saved in ./models/checkpoint-3000/config.json\n",
      "Model weights saved in ./models/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2781\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./models/checkpoint-4000\n",
      "Configuration saved in ./models/checkpoint-4000/config.json\n",
      "Model weights saved in ./models/checkpoint-4000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4190, training_loss=3.632416707405327, metrics={'train_runtime': 4804.2058, 'train_samples_per_second': 3.487, 'train_steps_per_second': 0.872, 'total_flos': 1944931429515264.0, 'train_loss': 3.632416707405327, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MtpPNj9oc4GT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtpPNj9oc4GT",
    "outputId": "34819b8e-fea7-4fb8-e293-c894abab5437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /content/models/checkpoint-4000/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3medium_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 2048,\n",
      "  \"n_special\": 0,\n",
      "  \"output_past\": true,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file /content/models/checkpoint-4000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/models/checkpoint-4000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_path = '/content/models/checkpoint-4000'\n",
    "trained_model = GPT2LMHeadModel.from_pretrained(model_checkpoint_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNUdt9HSjKlQ",
   "metadata": {
    "id": "zNUdt9HSjKlQ"
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NJJYkkmXE4JC",
   "metadata": {
    "id": "NJJYkkmXE4JC"
   },
   "outputs": [],
   "source": [
    "def generate_comment(mode_, temperature=1.0, top_k=15, top_p=1, beam_search=True):\n",
    "  begin = '[toxic]' if mode_ == 'toxic' else '[neutral]'\n",
    "  input_ids = tokenizer.encode(begin, return_tensors=\"pt\",).to(device)\n",
    "  out = trained_model.generate(input_ids, \n",
    "                               do_sample=True, \n",
    "                               temperature=temperature, \n",
    "                               top_k=top_k, \n",
    "                               top_p=top_p, \n",
    "                               beam_search=beam_search, \n",
    "                               max_length=50)\n",
    "  generated_text = list(map(tokenizer.decode, out))[0]\n",
    "  return generated_text.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c62280",
   "metadata": {},
   "source": [
    "–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D6K5GBBQFqU7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6K5GBBQFqU7",
    "outputId": "abaa2150-00f2-4e2a-a8ca-908dcc6958aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toxic] –Ø –≤ –∂–æ–ø–µ, –±–ª—è—Ö–∞ –º—É—Ö–∞.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toxic] –ê –ø–æ—á–µ–º—É —ç—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –æ–¥–Ω–æ–º –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –ø–æ—Å—Ç–æ–≤? –í —á–µ–º –ø—Ä–∏–∫–æ–ª?\n",
      "\n",
      "[toxic] –ê —Ç—ã –≤ –∫—É—Ä—Å–µ, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "  print(generate_comment('toxic'))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Ry1vf0u49Ar",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ry1vf0u49Ar",
    "outputId": "6fabf366-75fe-4e02-c94f-db877a026104"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toxic] –ù–µ –Ω–∞–¥–æ —Ç–∞–∫ –≥–æ–≤–æ—Ä–∏—Ç—å! –¢—ã —á—Ç–æ, –¥—É–º–∞–µ—à—å, —è —Ç—É—Ç –æ–¥–∏–Ω —Ç–∞–∫–æ–π?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toxic] –¢—É–ø–∞—è –∏ –∑–ª–∞—è –æ–±–µ–∑—å—è–Ω–∞.\n",
      "\n",
      "[toxic] –ò —Ç–∞–∫ –ø–æ –∫—Ä—É–≥—É. –ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å —á—Ç–æ –±—ã —Ç–≤–æ—è –±–∞—à–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –Ω–∞ –±–ª–∞–≥–æ —Å—Ç—Ä–∞–Ω—ã —Ç–æ —Ç–µ–±–µ –Ω–∞–¥–æ –∑–∞–ø—Ä–µ—Ç–∏—Ç—å —É–ø–æ—Ç—Ä–µ–±–ª—è—Ç—å –∞–ª–∫–æ–≥–æ–ª—å. –ß—Ç–æ –±—ã —Ç—ã –Ω–µ –≥–æ–≤–æ—Ä–∏–ª, —ç—Ç–æ –±—É–¥–µ—Ç –ª–∏—à—å –ø–æ–≤–æ–¥–æ–º –∫ —Ç–æ–º—É, —á—Ç–æ —Ç—ã –±—É–¥–µ—à—å –ø–∏–∑–¥–∏—Ç—å, —á—Ç–æ —Ç–≤–æ—è\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "  print(generate_comment('toxic', top_k=40, top_p=0.9, temperature=0.9))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ClRRVn_FVv-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ClRRVn_FVv-",
    "outputId": "be8a97da-9e3c-4f0e-e1d4-037b42fff34e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toxic] –¢—ã –Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å. –≠—Ç–æ –∂–µ —Ö–æ—Ö–ª—ã. –û–Ω–∏ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —Å—á–∏—Ç–∞—é—Ç —á—Ç–æ –ü—É—Ç–∏–Ω –∏ –ö–æ - —ç—Ç–æ –æ–Ω–∏. –ò –æ–Ω–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toxic] –ù–∞—Ö—É–π —Ç—ã –º–Ω–µ —ç—Ç–æ –ø–∏—à–µ—à—å? –ú–Ω–µ –ø–æ—Ö—É–π.\n",
      "\n",
      "[toxic] –ê —è —Å—á–∏—Ç–∞—é, —á—Ç–æ –µ—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –¥–µ–Ω—å–≥–∏, —Ç–æ —Ç—ã –º–æ–∂–µ—à—å –∫—É–ø–∏—Ç—å —á—Ç–æ —Ö–æ—á–µ—à—å. –ê –≤–æ—Ç –µ—Å–ª–∏ –Ω–µ—Ç, —Ç–æ —Ç—ã –¥–æ–ª–∂–µ–Ω —Å —ç—Ç–∏–º —Å–º–∏—Ä–∏—Ç—å—Å—è –∏ –∏–¥—Ç–∏ —Ä–∞–±–æ—Ç–∞—Ç—å.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "  print(generate_comment('toxic', top_k=40, top_p=0.99, temperature=0.6))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "koYdPp1rFVt4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koYdPp1rFVt4",
    "outputId": "47ff2002-4839-4615-9887-0db79e042ff6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neutral] –ê —É –º–µ–Ω—è –ø—Ä–æ—Å—Ç–æ –≤ –≥–æ–ª–æ–≤–µ –æ—Ç —Ç–∞–∫–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∞–∂ –º—ã—Å–ª–∏ —Ä–æ—è—Ç—Å—è. –≠—Ç–æ —á—Ç–æ-—Ç–æ —Å —á–µ–º-—Ç–æ.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neutral] –ü—Ä–æ—Å—Ç–æ —è –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ –≤ –†–æ—Å—Å–∏–∏ –≤–æ–æ–±—â–µ –º–æ–∂–Ω–æ —á—Ç–æ-—Ç–æ –¥–µ–ª–∞—Ç—å –±–µ–∑ –≥–æ—Å –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –ï—Å–ª–∏ —è —É–µ–¥—É –∫—É–¥–∞-—Ç–æ –∏ –±—É–¥—É —á—Ç–æ-—Ç–æ –¥–µ–ª–∞—Ç—å, –∫–∞–∫ —Ç–æ–≥–¥–∞ –±—É–¥—É—Ç –≤–µ—Å—Ç–∏—Å—è –¥–µ–ª–∞? –î–∞–∂–µ –µ—Å–ª–∏ —è –ø—Ä–æ—Å—Ç–æ —É–µ–¥—É –≤\n",
      "\n",
      "[neutral] –° –∫–∞–∂–¥—ã–º –≥–æ–¥–æ–º —ç—Ç–æ –≤—Å—ë –±–æ–ª—å—à–µ –∏ –±–æ–ª—å—à–µ.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "  print(generate_comment('neutral', top_k=40, top_p=0.95, temperature=1))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "akIBmpZCFYig",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akIBmpZCFYig",
    "outputId": "84d01766-bf19-4072-e88b-e123efeb5c8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neutral] –ï—Å–ª–∏ –í—ã —Å—á–∏—Ç–∞–µ—Ç–µ, —á—Ç–æ —ç—Ç–∞ —Å–µ—Ç—å —è–≤–ª—è–µ—Ç—Å—è –æ–¥–Ω–æ–π –∏–∑ –ª—É—á—à–∏—Ö, —Ç–æ –í—ã –æ—à–∏–±–∞–µ—Ç–µ—Å—å. –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–æ–º–ø–∞–Ω–∏—è —Å –º–Ω–æ–≥–æ–º–∏–ª–ª–∏–æ–Ω–Ω—ã–º –æ–±–æ—Ä–æ—Ç–æ–º, –Ω–æ –Ω–µ –±–æ–ª–µ–µ —Ç–æ–≥–æ.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neutral] –°–ø–∞—Å–∏–±–æ. –ù–µ –¥—É–º–∞–ª, —á—Ç–æ —Ç–∞–∫–∏–µ —É–º–Ω—ã–µ –ª—é–¥–∏ –º–æ–≥—É—Ç –ø–∏—Å–∞—Ç—å. –ò —á—Ç–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–∏–∞–ª—å–Ω–æ.\n",
      "\n",
      "[neutral] –°–ø–∞—Å–∏–±–æ, –ø–æ–ø—Ä–æ–±—É—é.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "  print(generate_comment('neutral', top_k=100, temperature=1.01))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wr6n6VilFYRO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wr6n6VilFYRO",
    "outputId": "7a2775f1-e4df-4d6d-a323-76af83cea1fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neutral] –Ø —Ç–∞–∫ –∂–µ –Ω–∞ –∞–ª–∏ –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞. –í –æ–±—â–µ–º –∏ —Ü–µ–ª–æ–º –Ω–µ –ø–ª–æ—Ö–æ. –ù–æ –¥–æ—Å—Ç–∞–≤–∫–∞ –Ω–µ —Ç–∞–∫–∞—è –¥–æ–ª–≥–∞—è –∏ –Ω–µ —Ç–∞–∫–∞—è —É–¥–æ–±–Ω–∞—è, –∫–∞–∫ –≤ –†–æ—Å—Å–∏–∏. –î–∞ –∏ –Ω–µ –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –≤ –Ω–∞–ª–∏—á–∏–∏ (–ø–æ –∫—Ä–∞–π–Ω–µ–π –º–µ—Ä–µ –¥–ª—è –†–æ—Å—Å–∏–∏)\n"
     ]
    }
   ],
   "source": [
    "print(generate_comment('neutral'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YCngBlAknX9O",
   "metadata": {
    "id": "YCngBlAknX9O"
   },
   "source": [
    "## –ü—Ä–∏–º–µ—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤:\n",
    "\n",
    "[toxic] –¢—É–ø–∞—è –∏ –∑–ª–∞—è –æ–±–µ–∑—å—è–Ω–∞.<br>\n",
    "[toxic] –ù–∞—Ö—É–π —Ç—ã –º–Ω–µ —ç—Ç–æ –ø–∏—à–µ—à—å? –ú–Ω–µ –ø–æ—Ö—É–π.<br>\n",
    "[toxic] –¢—ã –Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å. –≠—Ç–æ –∂–µ —Ö–æ—Ö–ª—ã. –û–Ω–∏ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —Å—á–∏—Ç–∞—é—Ç —á—Ç–æ –ü—É—Ç–∏–Ω –∏ –ö–æ - —ç—Ç–æ –æ–Ω–∏. –ò –æ–Ω–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫.<br>\n",
    "[toxic] –ê —è —Å—á–∏—Ç–∞—é, —á—Ç–æ –µ—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –¥–µ–Ω—å–≥–∏, —Ç–æ —Ç—ã –º–æ–∂–µ—à—å –∫—É–ø–∏—Ç—å —á—Ç–æ —Ö–æ—á–µ—à—å. –ê –≤–æ—Ç –µ—Å–ª–∏ –Ω–µ—Ç, —Ç–æ —Ç—ã –¥–æ–ª–∂–µ–Ω —Å —ç—Ç–∏–º —Å–º–∏—Ä–∏—Ç—å—Å—è –∏ –∏–¥—Ç–∏ —Ä–∞–±–æ—Ç–∞—Ç—å.<br><br>\n",
    "\n",
    "[neutral] –ü—Ä–æ—Å—Ç–æ —è –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ –≤ –†–æ—Å—Å–∏–∏ –≤–æ–æ–±—â–µ –º–æ–∂–Ω–æ —á—Ç–æ-—Ç–æ –¥–µ–ª–∞—Ç—å –±–µ–∑ –≥–æ—Å –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –ï—Å–ª–∏ —è —É–µ–¥—É –∫—É–¥–∞-—Ç–æ –∏ –±—É–¥—É —á—Ç–æ-—Ç–æ –¥–µ–ª–∞—Ç—å, –∫–∞–∫ —Ç–æ–≥–¥–∞ –±—É–¥—É—Ç –≤–µ—Å—Ç–∏—Å—è –¥–µ–ª–∞? –î–∞–∂–µ –µ—Å–ª–∏ —è –ø—Ä–æ—Å—Ç–æ —É–µ–¥—É –≤<br>\n",
    "[neutral] –°–ø–∞—Å–∏–±–æ. –ù–µ –¥—É–º–∞–ª, —á—Ç–æ —Ç–∞–∫–∏–µ —É–º–Ω—ã–µ –ª—é–¥–∏ –º–æ–≥—É—Ç –ø–∏—Å–∞—Ç—å. –ò —á—Ç–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–∏–∞–ª—å–Ω–æ.<br>\n",
    "[neutral] –ï—Å–ª–∏ –í—ã —Å—á–∏—Ç–∞–µ—Ç–µ, —á—Ç–æ —ç—Ç–∞ —Å–µ—Ç—å —è–≤–ª—è–µ—Ç—Å—è –æ–¥–Ω–æ–π –∏–∑ –ª—É—á—à–∏—Ö, —Ç–æ –í—ã –æ—à–∏–±–∞–µ—Ç–µ—Å—å. –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–æ–º–ø–∞–Ω–∏—è —Å –º–Ω–æ–≥–æ–º–∏–ª–ª–∏–æ–Ω–Ω—ã–º –æ–±–æ—Ä–æ—Ç–æ–º, –Ω–æ –Ω–µ –±–æ–ª–µ–µ —Ç–æ–≥–æ.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8437e8",
   "metadata": {
    "id": "ae8437e8"
   },
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ  2 (2 –±–∞–ª–ª–∞)\n",
    "\n",
    "–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:\n",
    "\n",
    "1) –í –∫–∞–∫–∏—Ö —Å—Ç–∞—Ç—å—è –±—ã–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã GPT-1, GPT-2, GPT-3?\n",
    "\n",
    "2) –ö–∞–∫ —Å–æ–±–∏—Ä–∞–ª—Å—è –æ–±—É—á–∞—é—â–∏–π –∫–æ—Ä–ø—É—Å –¥–ª—è GPT-3? –ö–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º —Å–æ–∑–¥–∞—Ç–µ–ª–∏ —Å—Ç–∞—Ä–∞–ª–∏—Å—å –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EfeLF9Chv2_L",
   "metadata": {
    "id": "EfeLF9Chv2_L"
   },
   "source": [
    "1) \n",
    "GPT-1 -Improving Language Understanding by Generative Pre-Training https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf<br>\n",
    "GPT-2 - Language Models are Unsupervised Multitask Learners https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf<br>\n",
    "GPT-3 - Language Models are Few-Shot Learners https://arxiv.org/pdf/2005.14165.pdf<br><br>\n",
    "\n",
    "2)\n",
    "–ó–∞ –æ—Å–Ω–æ–≤—É –±—ã–ª –≤–∑—è—Ç –¥–∞—Ç–∞—Å–µ—Ç CommonCrawl dataset.<br>\n",
    "–û–Ω –±—ã–ª –ø–æ—á–∏—â–µ–Ω —Å –ø–æ–º–æ—â—å—é –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º —Ç–µ–∫—Å—Ç–æ–º –∏ —Ç–µ–∫—Å—Ç–∞–º–∏ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (–ø–æ —Å—É—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∏ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –≥–¥–µ –∫–ª–∞—Å—Å–æ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —è–≤–ª—è–ª–∏—Å—å —Ç–µ–∫—Å—Ç—ã WebText, –∞ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π - Common Crawl Corpus). –ü–æ—Å–ª–µ —á–µ–≥–æ —Ç–µ–∫—Å—Ç—ã —Å –Ω–∏–∑–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –∫–ª–∞—Å—Å–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —É–¥–∞–ª—è–ª–∏—Å—å –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞.<br>\n",
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ (—É–¥–∞–ª–µ–Ω—ã —Ç–µ–∫—Å—Ç—ã —Å –±–æ–ª—å—à–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º —Å –¥—Ä—É–≥–∏–º–∏): –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è, –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏.<br>\n",
    "–ö –æ—Å–Ω–æ–≤–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É CommonCrawl –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã: WebText dataset, English Wiki, internet-based books (Books1, Books2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a5095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework_10_GPT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
