{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3440005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n",
      "C:\\Users\\huawei\\anaconda3\\lib\\site-packages\\pymorphy2\\units\\base.py:70: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, varargs, kw, default = inspect.getargspec(cls.__init__)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pyLDAvis.gensim_models\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler \n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ru_stopwords = get_stop_words('ru')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e5c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание  № 5. Матричные разложения/Тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18446b7",
   "metadata": {},
   "source": [
    "### Задание № 1 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81eecc",
   "metadata": {},
   "source": [
    "Попробуйте матричные разложения с 5 классификаторами - SGDClassifier, KNeighborsClassifier, MultinomialNB, RandomForest, ExtraTreesClassifier (про него подробнее почитайте в документации, он похож на RF). Используйте и NMF и SVD. Сравните результаты на кросс-валидации и выберите лучшее сочетание.\n",
    "\n",
    "В итоге у вас должно получиться, как минимум 10 моделей (два разложения на каждый классификатор). Используйте 1 и те же параметры кросс-валидации. Параметры векторизации, параметры K в матричных разложениях, параметры классификаторов могут быть разными между экспериментами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1760960",
   "metadata": {},
   "source": [
    "Можете взять поменьше данных, если все будет обучаться слишком долго (не ставьте параметр K слишком большим в NMF, иначе точно будет слишком долго)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b84d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18997c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14412 entries, 0 to 14411\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   comment  14412 non-null  object \n",
      " 1   toxic    14412 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 225.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51b11d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    9586\n",
       "1.0    4826\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283d4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation += '«»—-'\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 and word not in ru_stopwords and word not in punctuation]\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word in normalized_text]\n",
    "    return ' '.join(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20053155",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment_norm'] = data['comment'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "1db2b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_table(X, y, pipeline, N=3):\n",
    "    # зафиксируем порядок классов\n",
    "    labels = list(set(y))\n",
    "    \n",
    "    # метрики отдельных фолдов будет хранить в табличке\n",
    "    fold_metrics = pd.DataFrame(index=labels)\n",
    "    # дополнительно также соберем таблицу ошибок\n",
    "    errors = np.zeros((len(labels), len(labels)))\n",
    "    \n",
    "    # создаем стратегию кросс-валидации\n",
    "    # shuffle=True (перемешивание) - часто критично важно указать\n",
    "    # т.к. данные могут быть упорядочены и модель на этом обучится\n",
    "    kfold = StratifiedKFold(n_splits=N, shuffle=True, random_state=42)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X, y)):\n",
    "        # fit-predict как и раньше, но сразу пайплайном\n",
    "        pipeline.fit(X[train_index], y[train_index])\n",
    "        preds = pipeline.predict(X[test_index])\n",
    "        \n",
    "        # записываем метрику и индекс фолда\n",
    "        fold_metrics[f'precision_{i}'] = precision_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'recall_{i}'] = recall_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'f1_{i}'] = f1_score(y[test_index], preds, labels=labels, average=None)\n",
    "        errors += confusion_matrix(y[test_index], preds, labels=labels, normalize='true')\n",
    "    \n",
    "    # таблица для усредненных значений\n",
    "    # тут мы берем колонки со значениями и усредняем их\n",
    "    # часто также все метрики сразу суммируют и в конце просто делят на количество фолдов\n",
    "    # но мы тут помимо среднего также хотим посмотреть на стандартное отклонение\n",
    "    # чтобы понять как сильно варьируются оценки моделей\n",
    "    result = pd.DataFrame(index=labels)\n",
    "    result['precision'] = fold_metrics[[f'precision_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['precision_std'] = fold_metrics[[f'precision_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    result['recall'] = fold_metrics[[f'recall_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['recall_std'] = fold_metrics[[f'recall_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    result['f1'] = fold_metrics[[f'f1_{i}' for i in range(N)]].mean(axis=1).round(2)\n",
    "    result['f1_std'] = fold_metrics[[f'f1_{i}' for i in range(N)]].std(axis=1).round(2)\n",
    "    \n",
    "    # добавим одну колонку со средним по всем классам\n",
    "    result.loc['mean'] = result.mean().round(2)\n",
    "    # проценты ошибок просто усредняем\n",
    "    errors /= N\n",
    "    \n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9aef7",
   "metadata": {},
   "source": [
    "Все параметры моделей сначала подбирал на обычном train_test_split, чтобы понять какие должны быть, чтобы модели показывали хорошее качество. А потом уже делал кроссвалидацию. На NMF большие значения взять не получилось, слишком много времени занимало это разложение, да и качество хуже было при увеличении этого параметра, поэтому в этом особо смысла и не было."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d1917",
   "metadata": {},
   "source": [
    "<b>SGDClassifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "95347abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), max_df=0.5, stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='log', alpha=0.00001, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_svd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), max_df=0.5, stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', TruncatedSVD(100)),\n",
    "    ('clf', SGDClassifier(loss='log', alpha=0.00001, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_nmf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), max_df=0.5, stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', NMF(20)),\n",
    "    ('clf', SGDClassifier(loss='log', alpha=0.00001, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "2e2d2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bow, errors_bow = eval_table(data['comment_norm'], data['toxic'], pipeline_bow)\n",
    "metrics_svd, errors_svd = eval_table(data['comment_norm'], data['toxic'], pipeline_svd)\n",
    "metrics_nmf, errors_nmf = eval_table(data['comment_norm'], data['toxic'], pipeline_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0bfbd11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.86           0.01    0.96        0.00  0.91    0.00\n",
       "1.0        0.89           0.01    0.69        0.02  0.77    0.01\n",
       "mean       0.88           0.01    0.82        0.01  0.84    0.00"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e06f536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.84           0.04    0.91        0.07  0.87    0.01\n",
       "1.0        0.80           0.08    0.64        0.12  0.70    0.04\n",
       "mean       0.82           0.06    0.78        0.10  0.78    0.02"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a0702ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.76           0.08    0.92        0.11  0.82    0.01\n",
       "1.0        0.77           0.12    0.38        0.30  0.45    0.23\n",
       "mean       0.76           0.10    0.65        0.20  0.64    0.12"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c850613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98894131, 0.01105869],\n",
       "       [0.78969413, 0.21030587]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71293891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94325039, 0.05674961],\n",
       "       [0.6663919 , 0.3336081 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "8b73a77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92000029, 0.07999971],\n",
       "       [0.62135652, 0.37864348]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f0874",
   "metadata": {},
   "source": [
    "<b>Лучший результат показал BOW</b>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507dbef",
   "metadata": {},
   "source": [
    "<b>KNeighborsClassifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "08982aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), max_df=0.75, stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=20, weights='distance', metric='euclidean'))\n",
    "])\n",
    "\n",
    "pipeline_svd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), max_df=0.75, stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', TruncatedSVD(10)),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=20, weights='distance', metric='euclidean'))\n",
    "])\n",
    "\n",
    "pipeline_nmf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,2), max_df=0.5, stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', NMF(10)),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=20, weights='distance', metric='euclidean'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "41681fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bow, errors_bow = eval_table(data['comment_norm'], data['toxic'], pipeline_bow)\n",
    "metrics_svd, errors_svd = eval_table(data['comment_norm'], data['toxic'], pipeline_svd)\n",
    "metrics_nmf, errors_nmf = eval_table(data['comment_norm'], data['toxic'], pipeline_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "d412d89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.80           0.03    0.97        0.01  0.88    0.01\n",
       "1.0        0.90           0.02    0.53        0.08  0.66    0.06\n",
       "mean       0.85           0.02    0.75        0.04  0.77    0.03"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "30048356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.80           0.00    0.93        0.01  0.86     0.0\n",
       "1.0        0.79           0.02    0.53        0.00  0.63     0.0\n",
       "mean       0.80           0.01    0.73        0.00  0.74     0.0"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "07222614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.79           0.02    0.91        0.01  0.85    0.01\n",
       "1.0        0.74           0.04    0.52        0.04  0.61    0.04\n",
       "mean       0.76           0.03    0.72        0.02  0.73    0.02"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "680a7b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97026859, 0.02973141],\n",
       "       [0.47472924, 0.52527076]])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "5a197afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92729014, 0.07270986],\n",
       "       [0.46891771, 0.53108229]])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "0559bb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90913668, 0.09086332],\n",
       "       [0.47699533, 0.52300467]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb510c",
   "metadata": {},
   "source": [
    "<b>Лучший результат показал BOW</b>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b25dce",
   "metadata": {},
   "source": [
    "<b>MultinomialNB</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "184797fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), max_df=0.75, stop_words=ru_stopwords)),\n",
    "    ('clf', MultinomialNB(alpha=0.3))\n",
    "])\n",
    "\n",
    "pipeline_svd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), max_df=0.75, stop_words=ru_stopwords)),\n",
    "    ('svd', TruncatedSVD(50)),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clf', MultinomialNB(alpha=0.3))\n",
    "])\n",
    "\n",
    "pipeline_nmf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), max_df=0.75, stop_words=ru_stopwords)),\n",
    "    ('svd', NMF(5)),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clf', MultinomialNB(alpha=0.3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "decc2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bow, errors_bow = eval_table(data['comment_norm'], data['toxic'], pipeline_bow)\n",
    "metrics_svd, errors_svd = eval_table(data['comment_norm'], data['toxic'], pipeline_svd)\n",
    "metrics_nmf, errors_nmf = eval_table(data['comment_norm'], data['toxic'], pipeline_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "17e9cc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.89            0.0    0.93        0.00  0.91    0.00\n",
       "1.0        0.85            0.0    0.77        0.01  0.81    0.01\n",
       "mean       0.87            0.0    0.85        0.00  0.86    0.00"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "a2e3f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std   f1  f1_std\n",
       "0.0        0.67            0.0     1.0         0.0  0.8     0.0\n",
       "1.0        0.00            0.0     0.0         0.0  0.0     0.0\n",
       "mean       0.34            0.0     0.5         0.0  0.4     0.0"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "e62b4d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std   f1  f1_std\n",
       "0.0        0.67            0.0     1.0         0.0  0.8     0.0\n",
       "1.0        0.00            0.0     0.0         0.0  0.0     0.0\n",
       "mean       0.34            0.0     0.5         0.0  0.4     0.0"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "11d7d4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92958471, 0.07041529],\n",
       "       [0.23124575, 0.76875425]])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "f51c7468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "fd0a7f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f26dee",
   "metadata": {},
   "source": [
    "<b>Лучший результат показал BOW, матричные разложения не применимы для MultinomialNB</b>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7eb19",
   "metadata": {},
   "source": [
    "<b>RandomForest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "bef3c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier(max_depth=120, min_samples_leaf=4, n_estimators=400, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_svd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', TruncatedSVD(50)),\n",
    "    ('clf', RandomForestClassifier(max_depth=120, min_samples_leaf=4, n_estimators=400, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_nmf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', NMF(10)),\n",
    "    ('clf', RandomForestClassifier(max_depth=120, min_samples_leaf=4, n_estimators=400, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "84769663",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bow, errors_bow = eval_table(data['comment_norm'], data['toxic'], pipeline_bow)\n",
    "metrics_svd, errors_svd = eval_table(data['comment_norm'], data['toxic'], pipeline_svd)\n",
    "metrics_nmf, errors_nmf = eval_table(data['comment_norm'], data['toxic'], pipeline_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "4d91adee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.78           0.00    0.98        0.00  0.87    0.00\n",
       "1.0        0.93           0.01    0.44        0.01  0.59    0.01\n",
       "mean       0.86           0.00    0.71        0.00  0.73    0.00"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "56aa559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.83           0.01    0.93        0.01  0.87    0.01\n",
       "1.0        0.81           0.02    0.61        0.02  0.70    0.02\n",
       "mean       0.82           0.02    0.77        0.02  0.78    0.02"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "2aafe927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.80           0.00    0.90        0.00  0.85    0.00\n",
       "1.0        0.74           0.01    0.57        0.01  0.64    0.01\n",
       "mean       0.77           0.00    0.74        0.00  0.74    0.00"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "d62d0404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98351751, 0.01648249],\n",
       "       [0.56361359, 0.43638641]])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "96b1460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92676739, 0.07323261],\n",
       "       [0.38603311, 0.61396689]])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "83cfe783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8972463 , 0.1027537 ],\n",
       "       [0.43307108, 0.56692892]])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b67d1e",
   "metadata": {},
   "source": [
    "<b>Лучший результат показал BOW + SVD</b>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f51e02",
   "metadata": {},
   "source": [
    "<b>ExtraTreesClassifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "88944a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_bow = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', ExtraTreesClassifier(max_depth=60, min_samples_leaf=3, n_estimators=400, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_svd = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', TruncatedSVD(100)),\n",
    "    ('clf', ExtraTreesClassifier(max_depth=60, min_samples_leaf=3, n_estimators=400, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_nmf = Pipeline([\n",
    "    ('bow', CountVectorizer(tokenizer=lambda x: x.split(), ngram_range=(1,1), stop_words=ru_stopwords)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svd', NMF(10)),\n",
    "    ('clf', ExtraTreesClassifier(max_depth=60, min_samples_leaf=3, n_estimators=400, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "22656177",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bow, errors_bow = eval_table(data['comment_norm'], data['toxic'], pipeline_bow)\n",
    "metrics_svd, errors_svd = eval_table(data['comment_norm'], data['toxic'], pipeline_svd)\n",
    "metrics_nmf, errors_nmf = eval_table(data['comment_norm'], data['toxic'], pipeline_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "1ffa9001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.69            0.0    1.00         0.0  0.81    0.00\n",
       "1.0        0.98            0.0    0.10         0.0  0.18    0.01\n",
       "mean       0.84            0.0    0.55         0.0  0.50    0.00"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "5ca3b433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.79           0.00    0.95        0.00  0.86    0.00\n",
       "1.0        0.82           0.01    0.49        0.01  0.62    0.01\n",
       "mean       0.80           0.00    0.72        0.00  0.74    0.00"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "27c1e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  precision_std  recall  recall_std    f1  f1_std\n",
       "0.0        0.79           0.00    0.91        0.01  0.85    0.00\n",
       "1.0        0.75           0.01    0.52        0.01  0.62    0.01\n",
       "mean       0.77           0.00    0.72        0.01  0.74    0.00"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "3231b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9988525 , 0.0011475 ],\n",
       "       [0.90074629, 0.09925371]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "15b71f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94585854, 0.05414146],\n",
       "       [0.50642285, 0.49357715]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "852e873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91445785, 0.08554215],\n",
       "       [0.47928127, 0.52071873]])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e7c04",
   "metadata": {},
   "source": [
    "<b>Лучший результат показал BOW + SVD</b>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436142a",
   "metadata": {},
   "source": [
    "### Задание № 2 (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb61f26",
   "metadata": {},
   "source": [
    "В Gensim тоже можно добавить нграммы и tfidf. Постройте 1 модель без них (как в семинаре) и еще 3 модели (1 с нграммами, 1 с tfidf и 1 с нграммами и с tfidf). Сранивте качество с помощью метрик (перплексия, когерентность) и на глаз. Определите лучшую модель. Для каждой модели выберите 1 самую красивую на ваш взгляд тему.\n",
    "\n",
    "Используйте данные википедии из семинара. Можете взять поменьше данных, если все обучается долго.\n",
    "\n",
    "Важное требование - получившиеся модели не должны быть совсем плохими. Если хороших тем не получается, попробуйте настроить гиперпараметры, отфильтровать словарь по-другому. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f483a",
   "metadata": {},
   "source": [
    "Нграммы добавляются вот так (перед созданиеv словаря)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1933e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = open('wiki_data.txt', encoding='utf-8').read().splitlines()[:5000]\n",
    "texts = ([normalize(text) for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b32c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary([text.split() for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63958c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f6df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text.split()) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcfa8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaModel(corpus, \n",
    "                             num_topics=100, \n",
    "                             alpha='asymmetric', \n",
    "                             id2word=dictionary, \n",
    "                             passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e6b320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(98,\n",
       "  '0.112*\"банк\" + 0.046*\"кавказ\" + 0.039*\"дирижёр\" + 0.028*\"гимнастика\" + 0.027*\"чёрный\" + 0.026*\"ао\" + 0.021*\"радиостанция\" + 0.021*\"32\" + 0.020*\"край\" + 0.019*\"франция\"'),\n",
       " (99,\n",
       "  '0.025*\"’\" + 0.014*\"брак\" + 0.014*\"слово\" + 0.011*\"язык\" + 0.010*\"ребёнок\" + 0.008*\"другой\" + 0.008*\"форма\" + 0.007*\"образ\" + 0.007*\"например\" + 0.006*\"случай\"'),\n",
       " (97,\n",
       "  '0.039*\"самолёт\" + 0.016*\"авиационный\" + 0.016*\"полигон\" + 0.015*\"испытание\" + 0.014*\"воздушный\" + 0.012*\"аэродром\" + 0.011*\"вооружение\" + 0.011*\"полёт\" + 0.009*\"экипаж\" + 0.009*\"пилот\"'),\n",
       " (96,\n",
       "  '0.016*\"система\" + 0.008*\"должный\" + 0.006*\"данные\" + 0.006*\"информация\" + 0.006*\"условие\" + 0.006*\"случай\" + 0.005*\"цель\" + 0.005*\"возможность\" + 0.005*\"для\" + 0.005*\"проект\"'),\n",
       " (94,\n",
       "  '0.048*\"турнир\" + 0.047*\"финал\" + 0.038*\"раунд\" + 0.034*\"чемпионат\" + 0.031*\"выйти\" + 0.023*\"полуфинал\" + 0.022*\"четвертьфинал\" + 0.020*\"проиграть\" + 0.019*\"смочь\" + 0.016*\"сезон\"'),\n",
       " (95,\n",
       "  '0.074*\"премия\" + 0.056*\"роль\" + 0.051*\"хороший\" + 0.051*\"фильм\" + 0.038*\"сериал\" + 0.030*\"номинация\" + 0.023*\"американский\" + 0.023*\"награда\" + 0.018*\"категория\" + 0.017*\"лауреат\"'),\n",
       " (93,\n",
       "  '0.047*\"председатель\" + 0.044*\"совет\" + 0.039*\"государственный\" + 0.029*\"секретарь\" + 0.026*\"член\" + 0.022*\"комитет\" + 0.022*\"б\" + 0.020*\"заместитель\" + 0.018*\"деятель\" + 0.017*\"экономический\"'),\n",
       " (92,\n",
       "  '0.041*\"озеро\" + 0.031*\"северный\" + 0.019*\"км\" + 0.018*\"крупный\" + 0.018*\"берег\" + 0.016*\"север\" + 0.016*\"километр\" + 0.015*\"южный\" + 0.015*\"метр\" + 0.015*\"западный\"'),\n",
       " (91,\n",
       "  '0.039*\"альбом\" + 0.037*\"песня\" + 0.028*\"the\" + 0.012*\"of\" + 0.012*\"выпустить\" + 0.010*\"музыкальный\" + 0.010*\"американский\" + 0.009*\"сингл\" + 0.009*\"композиция\" + 0.008*\"записать\"'),\n",
       " (90,\n",
       "  '0.015*\"земля\" + 0.010*\"период\" + 0.010*\"культура\" + 0.008*\"древний\" + 0.006*\"существовать\" + 0.006*\"к\" + 0.006*\"современный\" + 0.006*\"крупный\" + 0.006*\"регион\" + 0.005*\"эпоха\"'),\n",
       " (9,\n",
       "  '0.069*\"подвеска\" + 0.043*\"автомобиль\" + 0.029*\"колесо\" + 0.022*\"поперечный\" + 0.020*\"поворот\" + 0.018*\"ось\" + 0.015*\"ход\" + 0.014*\"мост\" + 0.013*\"продольный\" + 0.013*\"движение\"'),\n",
       " (8,\n",
       "  '0.020*\"россия\" + 0.017*\"2009\" + 0.016*\"тыс\" + 0.015*\"фестиваль\" + 0.015*\"украинский\" + 0.013*\"2010\" + 0.013*\"2008\" + 0.012*\"российский\" + 0.011*\"2011\" + 0.011*\"2016\"'),\n",
       " (7,\n",
       "  '0.037*\"а\" + 0.027*\"оркестр\" + 0.025*\"п\" + 0.024*\"россия\" + 0.024*\"николай\" + 0.021*\"1956\" + 0.018*\"москва\" + 0.016*\"финляндия\" + 0.016*\"советский\" + 0.014*\"будапешт\"'),\n",
       " (6,\n",
       "  '0.041*\"король\" + 0.038*\"i\" + 0.032*\"ii\" + 0.018*\"французский\" + 0.015*\"франция\" + 0.012*\"император\" + 0.010*\"герцог\" + 0.009*\"iv\" + 0.009*\"де\" + 0.009*\"смерть\"'),\n",
       " (5,\n",
       "  '0.012*\"из-за\" + 0.009*\"команда\" + 0.007*\"джексон\" + 0.007*\"однако\" + 0.007*\"должный\" + 0.006*\"экспедиция\" + 0.006*\"удаться\" + 0.006*\"достигнуть\" + 0.005*\"пройти\" + 0.005*\"путь\"'),\n",
       " (4,\n",
       "  '0.104*\"река\" + 0.083*\"км\" + 0.050*\"берег\" + 0.043*\"посёлок\" + 0.043*\"совет\" + 0.038*\"расстояние\" + 0.037*\"сельский\" + 0.034*\"харьковский\" + 0.027*\"течение\" + 0.024*\"левый\"'),\n",
       " (3,\n",
       "  '0.017*\"римский\" + 0.014*\"медичи\" + 0.014*\"император\" + 0.009*\"сын\" + 0.009*\"род\" + 0.008*\"княжество\" + 0.008*\"воевода\" + 0.008*\"историк\" + 0.007*\"империя\" + 0.007*\"династия\"'),\n",
       " (2,\n",
       "  '0.057*\"соревнование\" + 0.051*\"спортсмен\" + 0.032*\"проводиться\" + 0.024*\"раунд\" + 0.023*\"результат\" + 0.022*\"прыжок\" + 0.022*\"спорт\" + 0.020*\"лёгкий\" + 0.019*\"квалификация\" + 0.019*\"атлетика\"'),\n",
       " (1,\n",
       "  '0.058*\"хутор\" + 0.030*\"ростовский\" + 0.027*\"список\" + 0.017*\"станица\" + 0.015*\"лагерь\" + 0.015*\"казачий\" + 0.011*\"поселение\" + 0.011*\"заключить\" + 0.009*\"сельский\" + 0.009*\"концлагерь\"'),\n",
       " (0,\n",
       "  '0.056*\"ракетка\" + 0.051*\"южный\" + 0.038*\"одиночный\" + 0.037*\"долгота\" + 0.037*\"хуан\" + 0.036*\"восточный\" + 0.034*\"румыния\" + 0.032*\"румынский\" + 0.029*\"северный\" + 0.028*\"океан\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8f0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(lda_model, num_topics=num_topics)\n",
    "    topics = []\n",
    "\n",
    "        for topic_id, topic in lda.show_topics(num_topics=num_topics, formatted=False):\n",
    "            topic = [word for word, _ in topic]\n",
    "            topics.append(topic)\n",
    "    return topics\n",
    "\n",
    "def get_coherence(lda_model, texts, dictionary):\n",
    "    topics = show_topics(lda_model, num_topics)\n",
    "    coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=[text.split() for text in texts], \n",
    "                                                   dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    coherence_val = coherence_model_lda.get_coherence()\n",
    "    return coherence_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0184dcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplixity:  269.93952343730285\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', np.exp2(-lda.log_perplexity(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bebf4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:  0.5944504122095\n"
     ]
    }
   ],
   "source": [
    "print('Coherence: ', get_coherence(lda, texts, dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567b71e",
   "metadata": {},
   "source": [
    "<b>Хороший пример:</b>\n",
    "\n",
    "(98,\n",
    "  '0.131*\"германия\" + 0.111*\"немецкий\" + 0.052*\"лагерь\" + 0.035*\"больница\" + 0.034*\"заключить\" + 0.029*\"мировой\" + 0.029*\"берлин\" + 0.025*\"медицинский\" + 0.023*\"нацистский\" + 0.022*\"концлагерь\"')\n",
    "  \n",
    "  (2,\n",
    "  '0.041*\"роль\" + 0.027*\"фильм\" + 0.011*\"американский\" + 0.010*\"играть\" + 0.009*\"актёр\" + 0.009*\"нью-йорк\" + 0.008*\"актриса\" + 0.008*\"сняться\" + 0.007*\"сыграть\" + 0.007*\"карьера\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d30ebc",
   "metadata": {},
   "source": [
    "Теперь добавим н-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "063bc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = [text.split() for text in texts]\n",
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.9) # threshold можно подбирать\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfe4f7",
   "metadata": {},
   "source": [
    "Н-граммы есть в корпусе, значит все ок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f176ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['новостройка',\n",
       "  'нижегородский',\n",
       "  'область',\n",
       "  'новостро́йка',\n",
       "  'сельский',\n",
       "  'посёлок',\n",
       "  'дивеевский',\n",
       "  'район',\n",
       "  'нижегородский',\n",
       "  'область',\n",
       "  'входить',\n",
       "  'состав',\n",
       "  'сатисский',\n",
       "  'сельсовет',\n",
       "  'посёлок',\n",
       "  'расположить',\n",
       "  '12,5',\n",
       "  'км',\n",
       "  'юг',\n",
       "  'село',\n",
       "  'дивеево',\n",
       "  '1',\n",
       "  'км',\n",
       "  'запад',\n",
       "  'город',\n",
       "  'саров',\n",
       "  'право',\n",
       "  'берег',\n",
       "  'река',\n",
       "  'вичкинза',\n",
       "  'правый',\n",
       "  'приток',\n",
       "  'река',\n",
       "  'сатис',\n",
       "  'окружить',\n",
       "  'смешанный',\n",
       "  'лес',\n",
       "  'соединить',\n",
       "  'асфальтовый',\n",
       "  'дорога',\n",
       "  'посёлок',\n",
       "  'цыгановка',\n",
       "  '1,5',\n",
       "  'км',\n",
       "  'грунтовый',\n",
       "  'просёлочный',\n",
       "  'дорога',\n",
       "  'посёлок',\n",
       "  'сатис',\n",
       "  '3,5',\n",
       "  'км',\n",
       "  'название',\n",
       "  'новостройка',\n",
       "  'являться',\n",
       "  'сугубо',\n",
       "  'официальный',\n",
       "  'местный',\n",
       "  'население',\n",
       "  'использовать',\n",
       "  'исключительно',\n",
       "  'альтернативный',\n",
       "  'название',\n",
       "  'хитрый',\n",
       "  'употребляться',\n",
       "  'языковой',\n",
       "  'оборот',\n",
       "  '…',\n",
       "  'хитрый',\n",
       "  'ранее',\n",
       "  'использовать',\n",
       "  'название',\n",
       "  'песчаный',\n",
       "  'известковый',\n",
       "  'основать',\n",
       "  '1920-й',\n",
       "  'год',\n",
       "  'переселенец',\n",
       "  'соседний',\n",
       "  'село',\n",
       "  'аламасовый',\n",
       "  'нарышкино',\n",
       "  'расположить',\n",
       "  'соответственно',\n",
       "  '8',\n",
       "  '14',\n",
       "  'км',\n",
       "  'запад',\n",
       "  'вознесенский',\n",
       "  'район',\n",
       "  'традиционно',\n",
       "  'посёлок',\n",
       "  'жить',\n",
       "  'рабочий',\n",
       "  'совхоз',\n",
       "  'вперёд',\n",
       "  'центр',\n",
       "  'посёлок',\n",
       "  'сатис',\n",
       "  'возле',\n",
       "  'посёлок',\n",
       "  'расположить',\n",
       "  'карьер',\n",
       "  'активно',\n",
       "  'добывать',\n",
       "  'доломитовый',\n",
       "  'мука',\n",
       "  'бутовый',\n",
       "  'камень',\n",
       "  'настоящий',\n",
       "  'официально',\n",
       "  'закрытый',\n",
       "  'по',\n",
       "  'данные',\n",
       "  '1978',\n",
       "  'посёлок',\n",
       "  'новостройка',\n",
       "  'характеризоваться',\n",
       "  'неперспективный',\n",
       "  'насчитываться',\n",
       "  '24',\n",
       "  'хозяйство',\n",
       "  '43',\n",
       "  'житель',\n",
       "  'водоснабжение',\n",
       "  'осуществляться',\n",
       "  'колодец',\n",
       "  'родниковый',\n",
       "  'учреждение',\n",
       "  'соцкультбыт',\n",
       "  'отсутствовать',\n",
       "  'в',\n",
       "  '1992',\n",
       "  'посёлок',\n",
       "  'насчитываться',\n",
       "  '7',\n",
       "  'хозяйство',\n",
       "  '16',\n",
       "  'житель',\n",
       "  '7',\n",
       "  'трудоспособный',\n",
       "  'возраст',\n",
       "  'на',\n",
       "  '1',\n",
       "  'январь',\n",
       "  '1995',\n",
       "  'посёлок',\n",
       "  'иметься',\n",
       "  '6',\n",
       "  'хозяйство',\n",
       "  '12',\n",
       "  'житель',\n",
       "  'в',\n",
       "  'настоящий',\n",
       "  'посёлок',\n",
       "  'оставаться',\n",
       "  'жилой',\n",
       "  'получить',\n",
       "  'развитие',\n",
       "  'благодаря',\n",
       "  'близость',\n",
       "  'святой',\n",
       "  'источник',\n",
       "  'в',\n",
       "  'полкилометра',\n",
       "  'расположить',\n",
       "  'казанский',\n",
       "  'родник',\n",
       "  '1,2',\n",
       "  'км',\n",
       "  'источник',\n",
       "  'святой',\n",
       "  'серафим_саровский',\n",
       "  'в',\n",
       "  'посёлок',\n",
       "  'расположить',\n",
       "  'скит',\n",
       "  'дивеевский',\n",
       "  'монастырь',\n",
       "  'в',\n",
       "  '2012',\n",
       "  'освятить',\n",
       "  'домовой',\n",
       "  'храм',\n",
       "  'честь',\n",
       "  'серафим_саровский'],\n",
       " ['эсмеральда',\n",
       "  'фильм',\n",
       "  '1905',\n",
       "  'эсмеральда',\n",
       "  'немой',\n",
       "  'короткометражный',\n",
       "  'драматический',\n",
       "  'фильм',\n",
       "  'режиссёр',\n",
       "  'алиса',\n",
       "  'ги-блаша',\n",
       "  '1873—1968',\n",
       "  'викторить',\n",
       "  'жасс',\n",
       "  '1862—1913',\n",
       "  'фильм',\n",
       "  'снятой',\n",
       "  'роман',\n",
       "  'виктор',\n",
       "  'гюго',\n",
       "  'премьера',\n",
       "  'состояться',\n",
       "  'франция',\n",
       "  '1905',\n",
       "  'фильм',\n",
       "  'считаться',\n",
       "  'самый',\n",
       "  'первый',\n",
       "  'фильм',\n",
       "  'снятой',\n",
       "  'роман',\n",
       "  'собор',\n",
       "  'парижский',\n",
       "  'богоматерь',\n",
       "  'фильм',\n",
       "  'рассказывать',\n",
       "  'жизнь',\n",
       "  'цыганский',\n",
       "  'красавица',\n",
       "  'эсмеральда',\n",
       "  'горбун',\n",
       "  'квазимодо',\n",
       "  'звонарь',\n",
       "  'собор',\n",
       "  'парижский',\n",
       "  'богоматерь'],\n",
       " ['список',\n",
       "  'остров',\n",
       "  'архипелаг',\n",
       "  'норденшёльд',\n",
       "  'это',\n",
       "  'рабочий',\n",
       "  'список',\n",
       "  'координация',\n",
       "  'создание',\n",
       "  'стать',\n",
       "  'остров',\n",
       "  'архипелаг',\n",
       "  'норденшёльд',\n",
       "  'жирный',\n",
       "  'выделить',\n",
       "  'относительно',\n",
       "  'крупный',\n",
       "  'остров',\n",
       "  'пометка',\n",
       "  'остров',\n",
       "  'обозначить',\n",
       "  'указанный',\n",
       "  'карта',\n",
       "  'частично',\n",
       "  '4',\n",
       "  'безымянный',\n",
       "  'остров',\n",
       "  'южный',\n",
       "  'побережье',\n",
       "  'остров',\n",
       "  'русский',\n",
       "  'безымянный',\n",
       "  'остров',\n",
       "  'юг',\n",
       "  'остров',\n",
       "  'ермолов']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text for text in ngrammed_texts[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "263c4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrammed_dictionary = gensim.corpora.Dictionary(ngrammed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4ed459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrammed_dictionary.filter_extremes(no_above=0.1, no_below=5)\n",
    "ngrammed_dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "797c8c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(14055 unique tokens: ['1,2', '1,5', '12', '12,5', '14']...)\n"
     ]
    }
   ],
   "source": [
    "print(ngrammed_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "733d34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrammed_corpus = [dictionary.doc2bow(text) for text in ngrammed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "74a9a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrammed_lda = gensim.models.LdaModel(ngrammed_corpus, \n",
    "                                      num_topics=100, \n",
    "                                      alpha='symmetric', \n",
    "                                      id2word=ngrammed_dictionary, \n",
    "                                      passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "54e74e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12,\n",
       "  '0.045*\"юридический\" + 0.043*\"поэтому\" + 0.026*\"послужить\" + 0.026*\"оказаться\" + 0.025*\"керамика\" + 0.024*\"указывать\" + 0.023*\"самолёт\" + 0.023*\"1874\" + 0.021*\"нью-йорк\" + 0.021*\"переживать\"'),\n",
       " (60,\n",
       "  '0.058*\"реформа\" + 0.053*\"1920\" + 0.046*\"способствовать\" + 0.040*\"йозеф\" + 0.028*\"давать\" + 0.019*\"регулирование\" + 0.017*\"техас\" + 0.017*\"вместе\" + 0.016*\"означать\" + 0.014*\"военачальник\"'),\n",
       " (98,\n",
       "  '0.077*\"увлекаться\" + 0.026*\"стан\" + 0.023*\"приписать\" + 0.020*\"коридор\" + 0.019*\"венгерский\" + 0.017*\"иоанн\" + 0.017*\"алексеевич\" + 0.015*\"рассесть\" + 0.015*\"внешность\" + 0.011*\"спина\"'),\n",
       " (14,\n",
       "  '0.042*\"продюсировать\" + 0.033*\"датировка\" + 0.028*\"закрытый\" + 0.025*\"содержаться\" + 0.023*\"1526\" + 0.023*\"прокуратура\" + 0.023*\"осуществить\" + 0.022*\"2005\" + 0.017*\"комиссариат\" + 0.017*\"кавалерийский\"'),\n",
       " (35,\n",
       "  '0.054*\"поэт\" + 0.052*\"роберт\" + 0.033*\"уйти\" + 0.022*\"контакт\" + 0.019*\"перестать\" + 0.018*\"достаточно\" + 0.017*\"повстанец\" + 0.016*\"собранный\" + 0.015*\"декорация\" + 0.013*\"угрожать\"'),\n",
       " (52,\n",
       "  '0.077*\"ужас\" + 0.030*\"создать\" + 0.024*\"шахта\" + 0.022*\"растение\" + 0.021*\"присвоить\" + 0.021*\"уездный\" + 0.016*\"пустынь\" + 0.015*\"собственный\" + 0.013*\"единый\" + 0.012*\"мюзикл\"'),\n",
       " (3,\n",
       "  '0.086*\"4,5\" + 0.069*\"томми\" + 0.034*\"сольный\" + 0.032*\"контактный\" + 0.031*\"тарелка\" + 0.030*\"стефан\" + 0.023*\"должность\" + 0.022*\"кэмерон\" + 0.022*\"машинист\" + 0.021*\"one\"'),\n",
       " (29,\n",
       "  '0.048*\"отправление\" + 0.022*\"харьковский\" + 0.016*\"создать\" + 0.015*\"министерство\" + 0.014*\"119\" + 0.013*\"банк\" + 0.013*\"постичь\" + 0.010*\"сухой\" + 0.009*\"микрорайон\" + 0.009*\"sony\"'),\n",
       " (8,\n",
       "  '0.059*\"печень\" + 0.046*\"гектар\" + 0.046*\"ориентировать\" + 0.023*\"соответствие\" + 0.016*\"а\" + 0.013*\"солидный\" + 0.010*\"ведение\" + 0.009*\"непосредственно\" + 0.009*\"стрельба\" + 0.008*\"женщина\"'),\n",
       " (91,\n",
       "  '0.043*\"оттуда\" + 0.039*\"орех\" + 0.031*\"усердие\" + 0.027*\"горнолыжник\" + 0.027*\"монтевидео\" + 0.024*\"предложить\" + 0.022*\"печень\" + 0.022*\"школьный\" + 0.021*\"контракт\" + 0.021*\"объединить\"'),\n",
       " (45,\n",
       "  '0.103*\"штраф\" + 0.072*\"близкородственный\" + 0.048*\"размещаться\" + 0.045*\"монография\" + 0.038*\"расхождение\" + 0.027*\"воровство\" + 0.025*\"материал\" + 0.025*\"несущий\" + 0.025*\"баварский\" + 0.024*\"вьетнам\"'),\n",
       " (6,\n",
       "  '0.006*\"империя\" + 0.006*\"например\" + 0.005*\"плохо\" + 0.005*\"2003\" + 0.005*\"кроме\" + 0.005*\"капсула\" + 0.005*\"джозеф\" + 0.005*\"список\" + 0.005*\"импорт\" + 0.005*\"англ\"'),\n",
       " (54,\n",
       "  '0.029*\"лавка\" + 0.021*\"лоуренс\" + 0.016*\"сольный\" + 0.014*\"сооружение\" + 0.014*\"фрейлина\" + 0.012*\"графство\" + 0.011*\"сохраниться\" + 0.011*\"астраханский\" + 0.010*\"вы\" + 0.010*\"руководство\"'),\n",
       " (59,\n",
       "  '0.043*\"учредить\" + 0.039*\"курс\" + 0.024*\"сша\" + 0.018*\"ничто\" + 0.015*\"грузия\" + 0.014*\"греция\" + 0.014*\"атака\" + 0.012*\"бронемашина\" + 0.010*\"становиться\" + 0.010*\"отличие\"'),\n",
       " (21,\n",
       "  '0.063*\"350\" + 0.042*\"преимущественно\" + 0.033*\"песчаник\" + 0.030*\"гуйян\" + 0.028*\"дар\" + 0.024*\"корабль\" + 0.023*\"репортаж\" + 0.023*\"тайвань\" + 0.022*\"сознание\" + 0.022*\"фраза\"'),\n",
       " (22,\n",
       "  '0.127*\"прерываться\" + 0.059*\"деревня\" + 0.046*\"шахта\" + 0.036*\"отец\" + 0.029*\"параллельно\" + 0.020*\"безымянный\" + 0.020*\"красавица\" + 0.019*\"сооружение\" + 0.019*\"всё-таки\" + 0.019*\"использоваться\"'),\n",
       " (11,\n",
       "  '0.224*\"престол\" + 0.122*\"далее\" + 0.089*\"железнодорожный\" + 0.052*\"прекращение\" + 0.041*\"исходить\" + 0.031*\"56\" + 0.024*\"проектный\" + 0.023*\"муниципалитет\" + 0.021*\"внешность\" + 0.019*\"тони\"'),\n",
       " (5,\n",
       "  '0.133*\"прерываться\" + 0.126*\"подруга\" + 0.091*\"покорить\" + 0.028*\"определять\" + 0.024*\"переезд\" + 0.022*\"владелец\" + 0.021*\"поместье\" + 0.021*\"целое\" + 0.021*\"телевизионный\" + 0.019*\"просёлочный\"'),\n",
       " (55,\n",
       "  '0.069*\"весна\" + 0.058*\"1727\" + 0.051*\"культура\" + 0.046*\"обеспечивать\" + 0.035*\"старик\" + 0.031*\"носитель\" + 0.031*\"водохранилище\" + 0.029*\"выясниться\" + 0.022*\"развивающийся\" + 0.020*\"призёр\"'),\n",
       " (23,\n",
       "  '0.071*\"питер\" + 0.048*\"правый\" + 0.043*\"сельсовет\" + 0.034*\"поставка\" + 0.033*\"карьер\" + 0.022*\"1905\" + 0.022*\"вечерний\" + 0.020*\"приспособление\" + 0.013*\"снятой\" + 0.011*\"причислить\"')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrammed_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "94372a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  267.6419379875327\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', np.exp2(-ngrammed_lda.log_perplexity(ngrammed_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98681737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.5906372721045241\n"
     ]
    }
   ],
   "source": [
    "print('Coherence:', get_coherence(ngrammed_lda, [' '.join(text) for text in ngrammed_texts], ngrammed_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec5e5c",
   "metadata": {},
   "source": [
    "Хороший пример:\n",
    "\n",
    "(60,\n",
    "  '0.058*\"реформа\" + 0.053*\"1920\" + 0.046*\"способствовать\" + 0.040*\"йозеф\" + 0.028*\"давать\" + 0.019*\"регулирование\" + 0.017*\"техас\" + 0.017*\"вместе\" + 0.016*\"означать\" + 0.014*\"военачальник\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6278",
   "metadata": {},
   "source": [
    "Теперь добавим tfidf к корпусу c н-граммами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "99dc224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(ngrammed_corpus, id2word=ngrammed_dictionary)\n",
    "ngrammed_tfidf_corpus = tfidf[ngrammed_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4a9ee0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrammed_tfidf_lda = gensim.models.LdaModel(ngrammed_tfidf_corpus,\n",
    "                                            40,\n",
    "                                            alpha='symmetric',\n",
    "                                            id2word=ngrammed_dictionary,\n",
    "                                            passes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "10492d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "  '0.022*\"гуйян\" + 0.017*\"боец\" + 0.013*\"зарабатывать\" + 0.013*\"дискриминация\" + 0.010*\"фантастика\" + 0.010*\"уважать\" + 0.008*\"исполнить\" + 0.008*\"филиал\" + 0.007*\"священнослужитель\" + 0.007*\"4-й\"'),\n",
       " (23,\n",
       "  '0.038*\"легальный\" + 0.016*\"легион\" + 0.009*\"джим\" + 0.008*\"маркиз\" + 0.006*\"мартынов\" + 0.006*\"комендант\" + 0.006*\"сечение\" + 0.006*\"прекращение\" + 0.006*\"неофициальный\" + 0.005*\"воровство\"'),\n",
       " (37,\n",
       "  '0.017*\"прохождение\" + 0.013*\"убивать\" + 0.013*\"проблемный\" + 0.012*\"средневековье\" + 0.011*\"ничто\" + 0.010*\"жестокий\" + 0.009*\"девочка\" + 0.008*\"призывать\" + 0.007*\"невский\" + 0.007*\"маркс\"'),\n",
       " (39,\n",
       "  '0.016*\"нога\" + 0.013*\"эссекс\" + 0.013*\"беспрецедентный\" + 0.011*\"поездка\" + 0.011*\"холокост\" + 0.008*\"эксплуатационный\" + 0.008*\"тут\" + 0.007*\"суммарный\" + 0.006*\"безуспешно\" + 0.005*\"лабораторный\"'),\n",
       " (8,\n",
       "  '0.026*\"лорд\" + 0.014*\"подозрение\" + 0.007*\"искусство\" + 0.007*\"сомнение\" + 0.006*\"аделаида\" + 0.006*\"1864\" + 0.005*\"узнать\" + 0.005*\"оскар\" + 0.005*\"60-й\" + 0.005*\"япония\"'),\n",
       " (18,\n",
       "  '0.038*\"джеймс\" + 0.004*\"франс\" + 0.003*\"подорвать\" + 0.002*\"автономия\" + 0.002*\"выставочный\" + 0.002*\"прокат\" + 0.001*\"начинать\" + 0.000*\"columbia\" + 0.000*\"вуз\" + 0.000*\"филиал\"'),\n",
       " (27,\n",
       "  '0.016*\"кульминация\" + 0.014*\"издательский\" + 0.012*\"воронцов\" + 0.011*\"xvi\" + 0.010*\"электрический\" + 0.010*\"курс\" + 0.008*\"особо\" + 0.006*\"вынести\" + 0.005*\"путь\" + 0.005*\"приданое\"'),\n",
       " (5,\n",
       "  '0.004*\"виктор\" + 0.003*\"пойти\" + 0.003*\"1886\" + 0.002*\"холодное\" + 0.002*\"жирный\" + 0.002*\"1727\" + 0.002*\"носитель\" + 0.002*\"правый\" + 0.002*\"вслед\" + 0.002*\"питер\"'),\n",
       " (38,\n",
       "  '0.019*\"причина\" + 0.016*\"проявляться\" + 0.009*\"потолок\" + 0.009*\"а\" + 0.008*\"протекать\" + 0.007*\"пенсионер\" + 0.007*\"администрация\" + 0.006*\"мониторинг\" + 0.006*\"34\" + 0.006*\"честь\"'),\n",
       " (17,\n",
       "  '0.016*\"носитель\" + 0.013*\"рыночный\" + 0.012*\"отработать\" + 0.010*\"основа\" + 0.009*\"управа\" + 0.008*\"августовский\" + 0.007*\"умение\" + 0.007*\"дзюдо\" + 0.006*\"адель\" + 0.006*\"мексика\"'),\n",
       " (35,\n",
       "  '0.028*\"режиссёр\" + 0.018*\"заработать\" + 0.018*\"уменьшение\" + 0.013*\"трое\" + 0.011*\"оставлять\" + 0.010*\"краевой\" + 0.010*\"2008\" + 0.010*\"металлургический\" + 0.010*\"39\" + 0.010*\"пётр\"'),\n",
       " (6,\n",
       "  '0.007*\"сложность\" + 0.005*\"25-й\" + 0.004*\"вода\" + 0.004*\"филологический\" + 0.004*\"издательство\" + 0.004*\"formula_7\" + 0.004*\"330\" + 0.004*\"инспекция\" + 0.003*\"сокращение\" + 0.003*\"обладать\"'),\n",
       " (20,\n",
       "  '0.015*\"роберт\" + 0.010*\"серьёзный\" + 0.010*\"поэт\" + 0.009*\"юнеско\" + 0.009*\"срок\" + 0.008*\"уйти\" + 0.008*\"смертельный\" + 0.007*\"перестать\" + 0.007*\"различие\" + 0.007*\"переименовать\"'),\n",
       " (34,\n",
       "  '0.014*\"каков\" + 0.010*\"зайцев\" + 0.007*\"педагогический\" + 0.007*\"казнить\" + 0.004*\"конфликт\" + 0.003*\"км\" + 0.002*\"эмигрант\" + 0.002*\"эстония\" + 0.002*\"госсовет\" + 0.001*\"юбилей\"'),\n",
       " (11,\n",
       "  '0.045*\"пересечение\" + 0.024*\"уровень\" + 0.024*\"многие\" + 0.019*\"изучение\" + 0.019*\"служение\" + 0.015*\"ожесточённый\" + 0.015*\"уе́зд\" + 0.013*\"стерлинг\" + 0.012*\"классификация\" + 0.010*\"скрываться\"'),\n",
       " (12,\n",
       "  '0.019*\"прийти\" + 0.012*\"командный\" + 0.008*\"обладательница\" + 0.007*\"неформальный\" + 0.007*\"бегать\" + 0.006*\"лист\" + 0.006*\"потребитель\" + 0.006*\"возможность\" + 0.006*\"магистратура\" + 0.005*\"доходный\"'),\n",
       " (1,\n",
       "  '0.029*\"расставаться\" + 0.018*\"мифология\" + 0.013*\"между\" + 0.009*\"конечный\" + 0.008*\"жалование\" + 0.007*\"позиция\" + 0.007*\"скрываться\" + 0.005*\"пользователь\" + 0.005*\"препятствие\" + 0.005*\"разрыв\"'),\n",
       " (31,\n",
       "  '0.027*\"шасси\" + 0.018*\"ничья\" + 0.016*\"физический\" + 0.014*\"системный\" + 0.013*\"кавалер\" + 0.013*\"вокальный\" + 0.007*\"изделие\" + 0.007*\"людмила\" + 0.005*\"ввиду\" + 0.005*\"закупка\"'),\n",
       " (26,\n",
       "  '0.013*\"различие\" + 0.010*\"метр\" + 0.008*\"ключевой\" + 0.008*\"антенна\" + 0.008*\"италия\" + 0.008*\"закарпатский\" + 0.007*\"кредит\" + 0.007*\"зима\" + 0.006*\"квартал\" + 0.006*\"карпаты\"'),\n",
       " (32,\n",
       "  '0.041*\"g\" + 0.028*\"польза\" + 0.017*\"рузвельт\" + 0.017*\"печень\" + 0.007*\"1867\" + 0.007*\"казах\" + 0.005*\"267\" + 0.005*\"предоставить\" + 0.004*\"залив\" + 0.004*\"изолировать\"')]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrammed_tfidf_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "22af4234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  18082125.771435328\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', np.exp2(-ngrammed_tfidf_lda.log_perplexity(ngrammed_tfidf_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6381a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  1008.5158559890915\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', np.exp2(-ngrammed_tfidf_lda.log_perplexity(ngrammed_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c9118e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence:  0.5906372721045241\n"
     ]
    }
   ],
   "source": [
    "print('Coherence: ', get_coherence(ngrammed_tfidf_lda, [' '.join(text) for text in ngrammed_texts], ngrammed_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa2e8f",
   "metadata": {},
   "source": [
    "Хорошие примеры:\n",
    "\n",
    "  '0.013*\"различие\" + 0.010*\"метр\" + 0.008*\"ключевой\" + 0.008*\"антенна\" + 0.008*\"италия\" + 0.008*\"закарпатский\" + 0.007*\"кредит\" + 0.007*\"зима\" + 0.006*\"квартал\" + 0.006*\"карпаты\"'),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02ef4b",
   "metadata": {},
   "source": [
    "Теперь будем использовать только tfidf без н-грамм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9b2f3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "tfidf_corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "17b192c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lda = gensim.models.LdaModel(tfidf_corpus, 100, alpha='symmetric', id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e63b87c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "  '0.033*\"дата\" + 0.024*\"петровский\" + 0.020*\"кардинал\" + 0.016*\"проведение\" + 0.012*\"трибуна\" + 0.008*\"1700\" + 0.000*\"василиевич\" + 0.000*\"ярославль\" + 0.000*\"денежный\" + 0.000*\"братский\"'),\n",
       " (46,\n",
       "  '0.027*\"церемония\" + 0.024*\"таблица\" + 0.024*\"спортсменка\" + 0.023*\"54\" + 0.023*\"ален\" + 0.019*\"microsoft\" + 0.019*\"запись\" + 0.018*\"солнечный\" + 0.017*\"windows\" + 0.016*\"грузовой\"'),\n",
       " (63,\n",
       "  '0.077*\"чемпионка\" + 0.033*\"wwe\" + 0.015*\"келли\" + 0.011*\"поединок\" + 0.008*\"чемпионский\" + 0.000*\"девушка\" + 0.000*\"шоу\" + 0.000*\"одержать\" + 0.000*\"титул\" + 0.000*\"победа\"'),\n",
       " (14,\n",
       "  '0.040*\"гарнизонный\" + 0.035*\"юрий\" + 0.023*\"портрет\" + 0.018*\"тетерев\" + 0.017*\"кавалерийский\" + 0.015*\"национальность\" + 0.012*\"распределение\" + 0.011*\"башкортостан\" + 0.010*\"антонио\" + 0.009*\"уфа\"'),\n",
       " (40,\n",
       "  '0.020*\"советский\" + 0.020*\"ленин\" + 0.019*\"орден\" + 0.019*\"фронт\" + 0.014*\"1-й\" + 0.014*\"аэропорт\" + 0.013*\"командир\" + 0.013*\"гвардейский\" + 0.013*\"ссср\" + 0.011*\"наградить\"'),\n",
       " (48,\n",
       "  '0.172*\"уезд\" + 0.073*\"округ\" + 0.038*\"городской\" + 0.031*\"упразднить\" + 0.031*\"империя\" + 0.026*\"провинция\" + 0.023*\"выделить\" + 0.022*\"преобразовать\" + 0.018*\"автономный\" + 0.016*\"управа\"'),\n",
       " (66,\n",
       "  '0.093*\"граф\" + 0.077*\"1968\" + 0.054*\"lotus\" + 0.045*\"графство\" + 0.034*\"де\" + 0.020*\"ii\" + 0.016*\"вероятно\" + 0.016*\"гоночный\" + 0.014*\"владение\" + 0.011*\"персидский\"'),\n",
       " (62,\n",
       "  '0.053*\"флаг\" + 0.035*\"шевченко\" + 0.028*\"символ\" + 0.023*\"диссертация\" + 0.022*\"доцент\" + 0.021*\"одесса\" + 0.021*\"виктор\" + 0.018*\"франсуа\" + 0.018*\"валерий\" + 0.017*\"ярмарка\"'),\n",
       " (72,\n",
       "  '0.046*\"россия\" + 0.028*\"майк\" + 0.023*\"козлов\" + 0.018*\"шон\" + 0.018*\"вольный\" + 0.016*\"окружный\" + 0.010*\"джонни\" + 0.008*\"экономика\" + 0.007*\"мистер\" + 0.004*\"поверить\"'),\n",
       " (0,\n",
       "  '0.071*\"фильм\" + 0.039*\"роль\" + 0.023*\"сериал\" + 0.016*\"актриса\" + 0.016*\"серия\" + 0.015*\"шоу\" + 0.013*\"персонаж\" + 0.013*\"друг\" + 0.011*\"чёрный\" + 0.011*\"сняться\"'),\n",
       " (26,\n",
       "  '0.032*\"св\" + 0.024*\"зависимость\" + 0.023*\"полк\" + 0.021*\"произвести\" + 0.020*\"чин\" + 0.017*\"братский\" + 0.017*\"георгий\" + 0.015*\"4-й\" + 0.014*\"реакция\" + 0.014*\"мемориал\"'),\n",
       " (86,\n",
       "  '0.201*\"летний\" + 0.083*\"спортсмен\" + 0.069*\"сборная\" + 0.068*\"женщина\" + 0.033*\"раунд\" + 0.024*\"соревнование\" + 0.022*\"дистанция\" + 0.022*\"2000\" + 0.021*\"атлетика\" + 0.020*\"австралия\"'),\n",
       " (19,\n",
       "  '0.073*\"бельгия\" + 0.023*\"чешский\" + 0.021*\"католический\" + 0.016*\"my\" + 0.015*\"варшава\" + 0.015*\"бельгийский\" + 0.012*\"рисунок\" + 0.011*\"and\" + 0.009*\"словацкий\" + 0.009*\"добавить\"'),\n",
       " (94,\n",
       "  '0.059*\"волость\" + 0.047*\"пункт\" + 0.047*\"населить\" + 0.040*\"сельсовет\" + 0.026*\"южный\" + 0.023*\"встречаться\" + 0.023*\"распространить\" + 0.023*\"уезд\" + 0.023*\"губерния\" + 0.019*\"деревня\"'),\n",
       " (30,\n",
       "  '0.137*\"подсемейство\" + 0.098*\"семейство\" + 0.052*\"род\" + 0.031*\"личинка\" + 0.029*\"роды\" + 0.019*\"триба\" + 0.019*\"растение\" + 0.016*\"усик\" + 0.016*\"щиток\" + 0.016*\"насекомое\"'),\n",
       " (15,\n",
       "  '0.045*\"программный\" + 0.041*\"заповедник\" + 0.028*\"1932\" + 0.019*\"охранять\" + 0.017*\"смирнов\" + 0.007*\"государственный\" + 0.005*\"пролетарский\" + 0.000*\"бюджет\" + 0.000*\"казахстан\" + 0.000*\"ректор\"'),\n",
       " (96,\n",
       "  '0.081*\"протекать\" + 0.029*\"саратовский\" + 0.028*\"через\" + 0.022*\"десант\" + 0.019*\"символизировать\" + 0.017*\"аэродром\" + 0.017*\"неполный\" + 0.012*\"пруд\" + 0.012*\"саратов\" + 0.011*\"авиация\"'),\n",
       " (9,\n",
       "  '0.046*\"перу\" + 0.044*\"1996\" + 0.028*\"атланта\" + 0.025*\"сша\" + 0.022*\"лёгкий\" + 0.020*\"суд\" + 0.017*\"долгота\" + 0.017*\"студийный\" + 0.015*\"штат\" + 0.012*\"александрович\"'),\n",
       " (84,\n",
       "  '0.141*\"1992\" + 0.101*\"мужчина\" + 0.029*\"love\" + 0.016*\"hot\" + 0.016*\"blue\" + 0.014*\"фигура\" + 0.014*\"in\" + 0.010*\"свеча\" + 0.010*\"хит\" + 0.009*\"фред\"'),\n",
       " (61,\n",
       "  '0.076*\"бронзовый\" + 0.076*\"серебряный\" + 0.036*\"пекин\" + 0.030*\"золотой\" + 0.021*\"азербайджан\" + 0.020*\"кг\" + 0.017*\"чемпион\" + 0.015*\"хор\" + 0.015*\"спорт\" + 0.015*\"карта\"')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5012120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5632385193307283\n"
     ]
    }
   ],
   "source": [
    "print('Coherence: ', get_coherence(tfidf_lda, [' '.join(text) for text in texts], dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75e7af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  76276958950.66371\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', np.exp2(-tfidf_lda.log_perplexity(tfidf_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "973328bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  583125.311014991\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', np.exp2(-tfidf_lda.log_perplexity(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67fadf1",
   "metadata": {},
   "source": [
    "Хорошие примеры:\n",
    "\n",
    "  '0.020*\"советский\" + 0.020*\"ленин\" + 0.019*\"орден\" + 0.019*\"фронт\" + 0.014*\"1-й\" + 0.014*\"аэропорт\" + 0.013*\"командир\" + 0.013*\"гвардейский\" + 0.013*\"ссср\" + 0.011*\"наградить\"'),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ba5db",
   "metadata": {},
   "source": [
    "Без нграмм модель работает гораздо лучше, и темы более качественные получаются. Хотя перплексия какая-то странная у tfidf моделей. Возможно проблема в десятичных значениях встречаемости токенов и словосочетаний. Но даже при подстановке обычного корпуса в формулу перплексии (не tfidf), получается плохое значение. Отпишите в комментарий пожалуйста, почему так. Хотя когеренция обладает хорошим значением, но все равно меньше чем у обычной модели на униграммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf46c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
