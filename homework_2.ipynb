{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "930b9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "from stop_words import get_stop_words\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from ftfy import fix_text\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "1fcf737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = get_stop_words('ru')\n",
    "punctuation += '«―_–»'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3705663",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "8bbc2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "1a19393f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                              Собаке - собачья смерть\\n    1.0\n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
       "...                                                  ...    ...\n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0\n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0\n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0\n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0\n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0\n",
       "\n",
       "[14412 rows x 2 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ca1b5",
   "metadata": {},
   "source": [
    "Дефолтный векторизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "01341538",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], data['toxic'], test_size=0.1, shuffle=True, stratify=data['toxic'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "60ea99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=russian_stopwords)\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "914eb285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "22cfe6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "c3d02b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.95      0.88       959\n",
      "         1.0       0.85      0.59      0.69       483\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.83      0.77      0.79      1442\n",
      "weighted avg       0.83      0.83      0.82      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "20ad5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "cvs = cross_val_score(lr, x_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "ffb5f88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000806993927755"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958e8be",
   "metadata": {},
   "source": [
    "Собственный векторизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "843437f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], data['toxic'], test_size=0.1, shuffle=True, stratify=data['toxic'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "5157bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    return [token.text.lower() for token in list(razdel_tokenize(text)) if token.text.lower() not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "1a22ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=russian_stopwords, tokenizer=my_tokenizer)\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "7934302a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "beac8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "6f0e07a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.94      0.88       959\n",
      "         1.0       0.84      0.60      0.70       483\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.83      0.77      0.79      1442\n",
      "weighted avg       0.83      0.83      0.82      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "6fda79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "cvs = cross_val_score(lr, x_train, y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "c1625f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7001020422819904"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b07ba7",
   "metadata": {},
   "source": [
    "Разницы почти нет, разве что f1-score для токсичных комментариев выше на 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa9f76",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f358949",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "c5b50abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {'я и ты': {'я': 1, 'ты': 1, 'и': 1, 'только': 0, 'не': 0, 'он': 0}, \n",
    "        'ты и я': {'я': 1, 'ты': 1, 'и': 1, 'только': 0, 'не': 0, 'он': 0}, \n",
    "        'я, я и только я': {'я': 3, 'ты': 0, 'и': 1, 'только': 1, 'не': 0, 'он': 0}, \n",
    "        'только не я': {'я': 1, 'ты': 0, 'и': 0, 'только': 1, 'не': 1, 'он': 0}, \n",
    "        'он': {'я': 0, 'ты': 0, 'и': 0, 'только': 0, 'не': 0, 'он': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "dd1d04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_rows = [[token for token in my_tokenizer(sent) if token not in punctuation] for sent in rows.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "8f851ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = {}\n",
    "\n",
    "for sent in tokenized_rows:\n",
    "    for token in set(sent):\n",
    "        if token in token_df:\n",
    "            token_df[token] += 1\n",
    "        else:\n",
    "            token_df[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "15ae7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "for string, keywords in rows.items():\n",
    "    for word, freq in keywords.items():\n",
    "        idf = len(keywords) / token_df[word]\n",
    "        tf = freq / sum(keywords.values())\n",
    "        tfidf = tf * idf\n",
    "        keywords[word] = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "0c5814ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.158455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   я   ты         и    только        не   он\n",
       "я и ты           0.5  1.2  0.740741  0.000000  0.000000  0.0\n",
       "ты и я           0.5  1.2  0.740741  0.000000  0.000000  0.0\n",
       "я, я и только я  0.9  0.0  0.689655  1.158455  0.000000  0.0\n",
       "только не я      0.5  0.0  0.000000  1.200000  2.222222  0.0\n",
       "он               0.0  0.0  0.000000  0.000000  0.000000  6.0"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(rows, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bc8de",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8961bbf",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46681ef",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "ed77d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "67836652",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment'] = data['comment'].apply(lambda x: re.sub('\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "aa3bdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], data['toxic'], test_size=0.1, shuffle=True, stratify=data['toxic'], random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=russian_stopwords, \n",
    "                                   ngram_range=(1,2),\n",
    "                                   max_df=0.999,\n",
    "                                   min_df=0.001,\n",
    "                                   tokenizer=my_tokenizer,\n",
    "                                   max_features=2000,\n",
    "                                   sublinear_tf=True)\n",
    "\n",
    "x_train_vect = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test_vect = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "efa4d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1e-1, \n",
    "                        random_state=42,\n",
    "                        class_weight='balanced',\n",
    "                        solver='newton-cg')\n",
    "\n",
    "lr.fit(x_train_vect, y_train)\n",
    "y_preds = lr.predict(x_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "9c75032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.82      0.85       959\n",
      "         1.0       0.68      0.78      0.73       483\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.78      0.80      0.79      1442\n",
      "weighted avg       0.82      0.81      0.81      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "d0368561",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reset_index()\n",
    "x_test['pred_proba'] = lr.predict_proba(x_test_vect)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "bf44186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "32c7398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст:  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\n",
      "Вероятность токсичности 0.92\n",
      "\n",
      "Текст:  Надо признать, хохлы унизили пидорах итт.\n",
      "Вероятность токсичности 0.86\n",
      "\n",
      "Текст:  У него хохлы были в предках.\n",
      "Вероятность токсичности 0.86\n",
      "\n",
      "Текст:  Это же хохлы для битья на зарплате. Там все по сценарию.\n",
      "Вероятность токсичности 0.86\n",
      "\n",
      "Текст:  Блядь, хохлы, вы бы хоть с проксей писали, няши тупые.\n",
      "Вероятность токсичности 0.86\n",
      "\n",
      "Текст:  Нахуй иди, щенок. мимо нульчер 2010\n",
      "Вероятность токсичности 0.85\n",
      "\n",
      "Текст:  Пиздец у быдла с пикабу сначала горело от негров на нулевой, теперь от скримеров, куда я нахуй попал, ебаные животные это БЭ, ЭТО РАНДОМ СУЧАРА, ТАМ НЕ ДОЛЖНО БЫТЬ ПРАВИЛ, ПОШЕЛ НАХУЙ\n",
      "Вероятность токсичности 0.84\n",
      "\n",
      "Текст:  Плюсы: -Какие же хохлы дегенераты, пиздец просто. Минусы: -Какие же хохлв дегенераты, пиздец просто.\n",
      "Вероятность токсичности 0.83\n",
      "\n",
      "Текст:  Не надо всю, Галицию нахуй надо слать, пусть пшеки забирают даром.\n",
      "Вероятность токсичности 0.82\n",
      "\n",
      "Текст:  Что? Какой денежный петух? Нет у хохлов своих сказок, коммуняки потом навыдумали хохлам культурку. А по факту то нация свинопасов и быдла, не городская. В том же Львове жили в основном поляки и евреи - городское население, а хохлы так. Быдло и селюки.\n",
      "Вероятность токсичности 0.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toxic_texts_lr = x_test.sort_values(by='pred_proba', ascending=False).head(10).values\n",
    "\n",
    "for text, prob in toxic_texts_lr:\n",
    "    print('Текст: ', text)\n",
    "    print('Вероятность токсичности', round(prob, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbe8af",
   "metadata": {},
   "source": [
    "Самое смешное, что почти все про хохлов) Тексты токсичные, хотя есть один без ругательств, но со словом \"хохлы\", но модель поняла, что там где есть \"хохлы\", то это коммент токсика, хотя по факту это может быть ошибочно и будет работать не везде. \n",
    "\n",
    "ПС в конце будет дополнение по этому поводу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "deaa063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['comment'], data['toxic'], test_size=0.1, shuffle=True, stratify=data['toxic'], random_state=42)\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words=russian_stopwords, \n",
    "                                   ngram_range=(1,1),\n",
    "                                   max_df=0.999,\n",
    "                                   min_df=0.001,\n",
    "                                   tokenizer=my_tokenizer\n",
    "                            )\n",
    "\n",
    "x_train_vect = count_vectorizer.fit_transform(x_train)\n",
    "x_test_vect = count_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "1bfd8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500,\n",
    "                            max_features='log2',\n",
    "                            min_samples_split=3\n",
    "                           )\n",
    "rf.fit(x_train_vect, y_train)\n",
    "\n",
    "y_preds = rf.predict(x_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "0b10a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85       959\n",
      "         1.0       0.70      0.73      0.72       483\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.78      0.79      0.78      1442\n",
      "weighted avg       0.81      0.81      0.81      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "fcd4d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reset_index()\n",
    "x_test['pred_proba'] = rf.predict_proba(x_test_vect)[:, 1]\n",
    "x_test.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "00465d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст:  То на них пьяное быдло просто так напало и они его убили пьяное быдло плиз\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Надо признать, хохлы унизили пидорах итт.\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Это же хохлы для битья на зарплате. Там все по сценарию.\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Ты дебил? Как тогда те самолеты, которые разбились, поднялись в воздух?\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  У него хохлы были в предках.\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Хохлоублюдки ответят за донбасс!!!\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Хул сука пугаешь падла\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Приятного сука аппетита.\n",
      "Вероятность токсичности 1.0\n",
      "\n",
      "Текст:  Все, едем в пендостан ебать тупых пендосских шлюх.\n",
      "Вероятность токсичности 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toxic_texts_rf = x_test[['comment', 'pred_proba']].sort_values(by='pred_proba', ascending=False).head(10).values\n",
    "\n",
    "for text, prob in toxic_texts_rf:\n",
    "    print('Текст: ', text)\n",
    "    print('Вероятность токсичности', round(prob, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18b8bc",
   "metadata": {},
   "source": [
    "Пересекающиеся комменты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "5844d1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.',\n",
       " 'Надо признать, хохлы унизили пидорах итт.',\n",
       " 'У него хохлы были в предках.',\n",
       " 'Это же хохлы для битья на зарплате. Там все по сценарию.'}"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(toxic_texts_rf[:, 0]) & set(toxic_texts_lr[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739a8bd",
   "metadata": {},
   "source": [
    "Различные комменты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "3cf13616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Все, едем в пендостан ебать тупых пендосских шлюх.',\n",
       " 'Приятного сука аппетита.',\n",
       " 'То на них пьяное быдло просто так напало и они его убили пьяное быдло плиз',\n",
       " 'Ты дебил? Как тогда те самолеты, которые разбились, поднялись в воздух?',\n",
       " 'Хохлоублюдки ответят за донбасс!!!',\n",
       " 'Хул сука пугаешь падла'}"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(toxic_texts_rf[:, 0]) - set(toxic_texts_lr[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "ad8350e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Блядь, хохлы, вы бы хоть с проксей писали, няши тупые.',\n",
       " 'Нахуй иди, щенок. мимо нульчер 2010',\n",
       " 'Не надо всю, Галицию нахуй надо слать, пусть пшеки забирают даром.',\n",
       " 'Пиздец у быдла с пикабу сначала горело от негров на нулевой, теперь от скримеров, куда я нахуй попал, ебаные животные это БЭ, ЭТО РАНДОМ СУЧАРА, ТАМ НЕ ДОЛЖНО БЫТЬ ПРАВИЛ, ПОШЕЛ НАХУЙ',\n",
       " 'Плюсы: -Какие же хохлы дегенераты, пиздец просто. Минусы: -Какие же хохлв дегенераты, пиздец просто.',\n",
       " 'Что? Какой денежный петух? Нет у хохлов своих сказок, коммуняки потом навыдумали хохлам культурку. А по факту то нация свинопасов и быдла, не городская. В том же Львове жили в основном поляки и евреи - городское население, а хохлы так. Быдло и селюки.'}"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(toxic_texts_lr[:, 0]) - set(toxic_texts_rf[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8cb1",
   "metadata": {},
   "source": [
    "В принципе везде токсичные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68324753",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7794f97",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "cda0b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_rf = pd.DataFrame(np.c_[np.array(list(count_vectorizer.get_feature_names())), rf.feature_importances_], columns=['token', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "2a553596",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_rf['coef'] = feat_imp_rf['coef'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "1621065d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>0.010296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>0.009894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>0.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>блядь</td>\n",
       "      <td>0.005671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>0.005350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token      coef\n",
       "2116   хохлы  0.010296\n",
       "2115  хохлов  0.009894\n",
       "1007   нахуй  0.007582\n",
       "141    блядь  0.005671\n",
       "1264  пиздец  0.005350"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_rf.sort_values(by='coef', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "7be03965",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_lr = pd.DataFrame(np.c_[np.array(list(tfidf_vectorizer.get_feature_names())), lr.coef_[0]], columns=['token', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "390e4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_lr['coef'] = feat_imp_lr['coef'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "e7ef24b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>хохлы</td>\n",
       "      <td>1.713794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>хохлов</td>\n",
       "      <td>1.635465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>нахуй</td>\n",
       "      <td>1.453508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>блядь</td>\n",
       "      <td>1.251428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>пиздец</td>\n",
       "      <td>1.189118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token      coef\n",
       "1911   хохлы  1.713794\n",
       "1910  хохлов  1.635465\n",
       "928    нахуй  1.453508\n",
       "135    блядь  1.251428\n",
       "1163  пиздец  1.189118"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_lr.sort_values(by='coef', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354ceed",
   "metadata": {},
   "source": [
    "Слова те же самые у обоих классификаторов, по поводу хохлов гипотеза подтвердилась, но в любом случае это слово возможно использовать вне контекста токсичного комментария (хотя тут не факт, видимо уже это понятие настолько трансформировалось, что упоминается только в негативном ключе)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
